{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sgkBP70X1LLB",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "933a2c6c-f86e-4db4-ae01-c4ad4b3eacec"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting selenium\n",
            "  Downloading selenium-4.23.1-py3-none-any.whl.metadata (7.1 kB)\n",
            "Requirement already satisfied: urllib3<3,>=1.26 in /usr/local/lib/python3.10/dist-packages (from urllib3[socks]<3,>=1.26->selenium) (2.0.7)\n",
            "Collecting trio~=0.17 (from selenium)\n",
            "  Downloading trio-0.26.2-py3-none-any.whl.metadata (8.6 kB)\n",
            "Collecting trio-websocket~=0.9 (from selenium)\n",
            "  Downloading trio_websocket-0.11.1-py3-none-any.whl.metadata (4.7 kB)\n",
            "Requirement already satisfied: certifi>=2021.10.8 in /usr/local/lib/python3.10/dist-packages (from selenium) (2024.7.4)\n",
            "Requirement already satisfied: typing_extensions~=4.9 in /usr/local/lib/python3.10/dist-packages (from selenium) (4.12.2)\n",
            "Requirement already satisfied: websocket-client~=1.8 in /usr/local/lib/python3.10/dist-packages (from selenium) (1.8.0)\n",
            "Requirement already satisfied: attrs>=23.2.0 in /usr/local/lib/python3.10/dist-packages (from trio~=0.17->selenium) (24.2.0)\n",
            "Requirement already satisfied: sortedcontainers in /usr/local/lib/python3.10/dist-packages (from trio~=0.17->selenium) (2.4.0)\n",
            "Requirement already satisfied: idna in /usr/local/lib/python3.10/dist-packages (from trio~=0.17->selenium) (3.7)\n",
            "Collecting outcome (from trio~=0.17->selenium)\n",
            "  Downloading outcome-1.3.0.post0-py2.py3-none-any.whl.metadata (2.6 kB)\n",
            "Requirement already satisfied: sniffio>=1.3.0 in /usr/local/lib/python3.10/dist-packages (from trio~=0.17->selenium) (1.3.1)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from trio~=0.17->selenium) (1.2.2)\n",
            "Collecting wsproto>=0.14 (from trio-websocket~=0.9->selenium)\n",
            "  Downloading wsproto-1.2.0-py3-none-any.whl.metadata (5.6 kB)\n",
            "Requirement already satisfied: pysocks!=1.5.7,<2.0,>=1.5.6 in /usr/local/lib/python3.10/dist-packages (from urllib3[socks]<3,>=1.26->selenium) (1.7.1)\n",
            "Collecting h11<1,>=0.9.0 (from wsproto>=0.14->trio-websocket~=0.9->selenium)\n",
            "  Downloading h11-0.14.0-py3-none-any.whl.metadata (8.2 kB)\n",
            "Downloading selenium-4.23.1-py3-none-any.whl (9.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m9.4/9.4 MB\u001b[0m \u001b[31m50.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading trio-0.26.2-py3-none-any.whl (475 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m476.0/476.0 kB\u001b[0m \u001b[31m20.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading trio_websocket-0.11.1-py3-none-any.whl (17 kB)\n",
            "Downloading wsproto-1.2.0-py3-none-any.whl (24 kB)\n",
            "Downloading outcome-1.3.0.post0-py2.py3-none-any.whl (10 kB)\n",
            "Downloading h11-0.14.0-py3-none-any.whl (58 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.3/58.3 kB\u001b[0m \u001b[31m3.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: outcome, h11, wsproto, trio, trio-websocket, selenium\n",
            "Successfully installed h11-0.14.0 outcome-1.3.0.post0 selenium-4.23.1 trio-0.26.2 trio-websocket-0.11.1 wsproto-1.2.0\n",
            "Hit:1 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/x86_64  InRelease\n",
            "Get:2 https://cloud.r-project.org/bin/linux/ubuntu jammy-cran40/ InRelease [3,626 B]\n",
            "Get:3 http://security.ubuntu.com/ubuntu jammy-security InRelease [129 kB]\n",
            "Hit:4 http://archive.ubuntu.com/ubuntu jammy InRelease\n",
            "Get:5 http://archive.ubuntu.com/ubuntu jammy-updates InRelease [128 kB]\n",
            "Ign:6 https://r2u.stat.illinois.edu/ubuntu jammy InRelease\n",
            "Get:7 https://r2u.stat.illinois.edu/ubuntu jammy Release [5,713 B]\n",
            "Hit:8 https://ppa.launchpadcontent.net/deadsnakes/ppa/ubuntu jammy InRelease\n",
            "Get:9 https://r2u.stat.illinois.edu/ubuntu jammy Release.gpg [793 B]\n",
            "Hit:10 https://ppa.launchpadcontent.net/graphics-drivers/ppa/ubuntu jammy InRelease\n",
            "Get:11 http://archive.ubuntu.com/ubuntu jammy-backports InRelease [127 kB]\n",
            "Get:12 http://security.ubuntu.com/ubuntu jammy-security/universe amd64 Packages [1,133 kB]\n",
            "Hit:13 https://ppa.launchpadcontent.net/ubuntugis/ppa/ubuntu jammy InRelease\n",
            "Get:14 http://archive.ubuntu.com/ubuntu jammy-updates/restricted amd64 Packages [2,963 kB]\n",
            "Get:15 http://security.ubuntu.com/ubuntu jammy-security/restricted amd64 Packages [2,867 kB]\n",
            "Get:16 https://r2u.stat.illinois.edu/ubuntu jammy/main amd64 Packages [2,553 kB]\n",
            "Get:17 http://security.ubuntu.com/ubuntu jammy-security/main amd64 Packages [2,171 kB]\n",
            "Get:18 http://archive.ubuntu.com/ubuntu jammy-updates/universe amd64 Packages [1,423 kB]\n",
            "Get:19 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 Packages [2,447 kB]\n",
            "Get:20 http://archive.ubuntu.com/ubuntu jammy-backports/universe amd64 Packages [33.7 kB]\n",
            "Fetched 16.0 MB in 4s (3,817 kB/s)\n",
            "Reading package lists... Done\n",
            "W: Skipping acquire of configured file 'main/source/Sources' as repository 'https://r2u.stat.illinois.edu/ubuntu jammy InRelease' does not seem to provide it (sources.list entry misspelt?)\n",
            "Reading package lists... Done\n",
            "Building dependency tree... Done\n",
            "Reading state information... Done\n",
            "The following additional packages will be installed:\n",
            "  apparmor chromium-browser libfuse3-3 liblzo2-2 libudev1 snapd squashfs-tools systemd-hwe-hwdb\n",
            "  udev\n",
            "Suggested packages:\n",
            "  apparmor-profiles-extra apparmor-utils fuse3 zenity | kdialog\n",
            "The following NEW packages will be installed:\n",
            "  apparmor chromium-browser chromium-chromedriver libfuse3-3 liblzo2-2 snapd squashfs-tools\n",
            "  systemd-hwe-hwdb udev\n",
            "The following packages will be upgraded:\n",
            "  libudev1\n",
            "1 upgraded, 9 newly installed, 0 to remove and 44 not upgraded.\n",
            "Need to get 28.5 MB of archives.\n",
            "After this operation, 118 MB of additional disk space will be used.\n",
            "Get:1 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 apparmor amd64 3.0.4-2ubuntu2.3 [595 kB]\n",
            "Get:2 http://archive.ubuntu.com/ubuntu jammy/main amd64 liblzo2-2 amd64 2.10-2build3 [53.7 kB]\n",
            "Get:3 http://archive.ubuntu.com/ubuntu jammy/main amd64 squashfs-tools amd64 1:4.5-3build1 [159 kB]\n",
            "Get:4 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 libudev1 amd64 249.11-0ubuntu3.12 [78.2 kB]\n",
            "Get:5 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 udev amd64 249.11-0ubuntu3.12 [1,557 kB]\n",
            "Get:6 http://archive.ubuntu.com/ubuntu jammy/main amd64 libfuse3-3 amd64 3.10.5-1build1 [81.2 kB]\n",
            "Get:7 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 snapd amd64 2.63+22.04ubuntu0.1 [25.9 MB]\n",
            "Get:8 http://archive.ubuntu.com/ubuntu jammy-updates/universe amd64 chromium-browser amd64 1:85.0.4183.83-0ubuntu2.22.04.1 [49.2 kB]\n",
            "Get:9 http://archive.ubuntu.com/ubuntu jammy-updates/universe amd64 chromium-chromedriver amd64 1:85.0.4183.83-0ubuntu2.22.04.1 [2,308 B]\n",
            "Get:10 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 systemd-hwe-hwdb all 249.11.5 [3,228 B]\n",
            "Fetched 28.5 MB in 4s (6,750 kB/s)\n",
            "Preconfiguring packages ...\n",
            "Selecting previously unselected package apparmor.\n",
            "(Reading database ... 123594 files and directories currently installed.)\n",
            "Preparing to unpack .../apparmor_3.0.4-2ubuntu2.3_amd64.deb ...\n",
            "Unpacking apparmor (3.0.4-2ubuntu2.3) ...\n",
            "Selecting previously unselected package liblzo2-2:amd64.\n",
            "Preparing to unpack .../liblzo2-2_2.10-2build3_amd64.deb ...\n",
            "Unpacking liblzo2-2:amd64 (2.10-2build3) ...\n",
            "Selecting previously unselected package squashfs-tools.\n",
            "Preparing to unpack .../squashfs-tools_1%3a4.5-3build1_amd64.deb ...\n",
            "Unpacking squashfs-tools (1:4.5-3build1) ...\n",
            "Preparing to unpack .../libudev1_249.11-0ubuntu3.12_amd64.deb ...\n",
            "Unpacking libudev1:amd64 (249.11-0ubuntu3.12) over (249.11-0ubuntu3.10) ...\n",
            "Setting up libudev1:amd64 (249.11-0ubuntu3.12) ...\n",
            "Selecting previously unselected package udev.\n",
            "(Reading database ... 123802 files and directories currently installed.)\n",
            "Preparing to unpack .../udev_249.11-0ubuntu3.12_amd64.deb ...\n",
            "Unpacking udev (249.11-0ubuntu3.12) ...\n",
            "Selecting previously unselected package libfuse3-3:amd64.\n",
            "Preparing to unpack .../libfuse3-3_3.10.5-1build1_amd64.deb ...\n",
            "Unpacking libfuse3-3:amd64 (3.10.5-1build1) ...\n",
            "Selecting previously unselected package snapd.\n",
            "Preparing to unpack .../snapd_2.63+22.04ubuntu0.1_amd64.deb ...\n",
            "Unpacking snapd (2.63+22.04ubuntu0.1) ...\n",
            "Setting up apparmor (3.0.4-2ubuntu2.3) ...\n",
            "Created symlink /etc/systemd/system/sysinit.target.wants/apparmor.service → /lib/systemd/system/apparmor.service.\n",
            "Setting up liblzo2-2:amd64 (2.10-2build3) ...\n",
            "Setting up squashfs-tools (1:4.5-3build1) ...\n",
            "Setting up udev (249.11-0ubuntu3.12) ...\n",
            "invoke-rc.d: could not determine current runlevel\n",
            "invoke-rc.d: policy-rc.d denied execution of start.\n",
            "Setting up libfuse3-3:amd64 (3.10.5-1build1) ...\n",
            "Setting up snapd (2.63+22.04ubuntu0.1) ...\n",
            "Created symlink /etc/systemd/system/multi-user.target.wants/snapd.apparmor.service → /lib/systemd/system/snapd.apparmor.service.\n",
            "Created symlink /etc/systemd/system/multi-user.target.wants/snapd.autoimport.service → /lib/systemd/system/snapd.autoimport.service.\n",
            "Created symlink /etc/systemd/system/multi-user.target.wants/snapd.core-fixup.service → /lib/systemd/system/snapd.core-fixup.service.\n",
            "Created symlink /etc/systemd/system/multi-user.target.wants/snapd.recovery-chooser-trigger.service → /lib/systemd/system/snapd.recovery-chooser-trigger.service.\n",
            "Created symlink /etc/systemd/system/multi-user.target.wants/snapd.seeded.service → /lib/systemd/system/snapd.seeded.service.\n",
            "Created symlink /etc/systemd/system/cloud-final.service.wants/snapd.seeded.service → /lib/systemd/system/snapd.seeded.service.\n",
            "Unit /lib/systemd/system/snapd.seeded.service is added as a dependency to a non-existent unit cloud-final.service.\n",
            "Created symlink /etc/systemd/system/multi-user.target.wants/snapd.service → /lib/systemd/system/snapd.service.\n",
            "Created symlink /etc/systemd/system/timers.target.wants/snapd.snap-repair.timer → /lib/systemd/system/snapd.snap-repair.timer.\n",
            "Created symlink /etc/systemd/system/sockets.target.wants/snapd.socket → /lib/systemd/system/snapd.socket.\n",
            "Created symlink /etc/systemd/system/final.target.wants/snapd.system-shutdown.service → /lib/systemd/system/snapd.system-shutdown.service.\n",
            "Selecting previously unselected package chromium-browser.\n",
            "(Reading database ... 124032 files and directories currently installed.)\n",
            "Preparing to unpack .../chromium-browser_1%3a85.0.4183.83-0ubuntu2.22.04.1_amd64.deb ...\n",
            "=> Installing the chromium snap\n",
            "==> Checking connectivity with the snap store\n",
            "===> System doesn't have a working snapd, skipping\n",
            "Unpacking chromium-browser (1:85.0.4183.83-0ubuntu2.22.04.1) ...\n",
            "Selecting previously unselected package chromium-chromedriver.\n",
            "Preparing to unpack .../chromium-chromedriver_1%3a85.0.4183.83-0ubuntu2.22.04.1_amd64.deb ...\n",
            "Unpacking chromium-chromedriver (1:85.0.4183.83-0ubuntu2.22.04.1) ...\n",
            "Selecting previously unselected package systemd-hwe-hwdb.\n",
            "Preparing to unpack .../systemd-hwe-hwdb_249.11.5_all.deb ...\n",
            "Unpacking systemd-hwe-hwdb (249.11.5) ...\n",
            "Setting up systemd-hwe-hwdb (249.11.5) ...\n",
            "Setting up chromium-browser (1:85.0.4183.83-0ubuntu2.22.04.1) ...\n",
            "update-alternatives: using /usr/bin/chromium-browser to provide /usr/bin/x-www-browser (x-www-browser) in auto mode\n",
            "update-alternatives: using /usr/bin/chromium-browser to provide /usr/bin/gnome-www-browser (gnome-www-browser) in auto mode\n",
            "Setting up chromium-chromedriver (1:85.0.4183.83-0ubuntu2.22.04.1) ...\n",
            "Processing triggers for udev (249.11-0ubuntu3.12) ...\n",
            "Processing triggers for hicolor-icon-theme (0.17-2) ...\n",
            "Processing triggers for libc-bin (2.35-0ubuntu3.4) ...\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbbind_2_5.so.3 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbmalloc_proxy.so.2 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libur_adapter_opencl.so.0 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libur_loader.so.0 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libur_adapter_level_zero.so.0 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbmalloc.so.2 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbb.so.12 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbbind_2_0.so.3 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbbind.so.3 is not a symbolic link\n",
            "\n",
            "Processing triggers for man-db (2.10.2-1) ...\n",
            "Processing triggers for dbus (1.12.20-2ubuntu4.1) ...\n",
            "cp: '/usr/lib/chromium-browser/chromedriver' and '/usr/bin/chromedriver' are the same file\n"
          ]
        }
      ],
      "source": [
        "!pip install selenium\n",
        "!apt-get update\n",
        "!apt install -y chromium-chromedriver\n",
        "!cp /usr/lib/chromium-browser/chromedriver /usr/bin"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from selenium.webdriver import Remote, ChromeOptions\n",
        "from selenium.webdriver.chromium.remote_connection import ChromiumRemoteConnection\n",
        "from selenium.webdriver.common.by import By\n",
        "\n",
        "from selenium.webdriver.support.ui import WebDriverWait\n",
        "from selenium.webdriver.support import expected_conditions as EC\n",
        "\n",
        "from bs4 import BeautifulSoup\n",
        "import requests\n",
        "import warnings\n",
        "import time\n",
        "import json\n",
        "\n",
        "from google.colab import files"
      ],
      "metadata": {
        "id": "iXmjmMdzlNi6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "지역명, 체크인 날짜, 체크아웃 날짜, 인원 수를 입력하면 그것에 맞는 호텔 정보를 가져올 수 있게 함.\n",
        "\n",
        "쿠팡 영상으로 크롤링을 먼저 공부한 후 건우님이 주신 코드를 참고하여 크롤링하려 했으나, JSON을 다루는 것이 익숙하지 않아 내부 코드를 수정하는 것이 어려웠음.\n",
        "\n",
        "그래서 쿠팡 영상에서 배운 내용을 바탕으로 beautifulsoup으로 각 상품에 접속하는 링크를 리스트에 모은 후 각각의 링크에 들어가서 정보들을 수집하는 방법이나, selenium으로 직접 링크들을 클릭하고 들어가서 정보들을 수집할 수 있는 방법을 적용해 보려했으나 과정에서 계속 오류가 발생함.\n",
        "\n",
        "다음주까지 다시 공부하고 찾아보며 오류를 해결해 나갈 예정."
      ],
      "metadata": {
        "id": "dWBersTSm5rw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 경고 문구 제거\n",
        "warnings.filterwarnings(\"ignore\", category=requests.packages.urllib3.exceptions.InsecureRequestWarning)\n",
        "\n",
        "# bright data\n",
        "AUTH = 'brd-customer-hl_6b1e4e16-zone-scraping_browser1:57gtuhxt7jou'\n",
        "SBR_WEBDRIVER = f'https://{AUTH}@zproxy.lum-superproxy.io:9515'\n",
        "\n",
        "# 총 검색 호텔 개수 및 총 검색 페이지 수 계산\n",
        "def get_total_page_num(region, start_date, end_date, person):\n",
        "  url = f\"https://www.yeogi.com/domestic-accommodations?searchType=KEYWORD&keyword={region}&autoKeyword=&checkIn={start_date}&checkOut={end_date}&personal={person}&freeForm=false&page=1\"\n",
        "  print(url)\n",
        "  print('Connecting to Scraping Browser...')\n",
        "  sbr_connection = ChromiumRemoteConnection(SBR_WEBDRIVER, 'goog', 'chrome')\n",
        "\n",
        "  with Remote(sbr_connection, options=ChromeOptions()) as driver:\n",
        "      print('Connected! Navigating...')\n",
        "      driver.get(url)\n",
        "      html = driver.page_source\n",
        "      soup = BeautifulSoup(html, \"html.parser\")\n",
        "\n",
        "      try:\n",
        "         WebDriverWait(driver, 10).until(EC.presence_of_element_located((By.CSS_SELECTOR, \"header.css-1psit91 h1\")))\n",
        "         h1_tag = driver.find_element(By.CSS_SELECTOR, \"header.css-1psit91 h1\")\n",
        "         total_result_text = h1_tag.text.strip()\n",
        "         total_result_num = \"\".join(char for char in total_result_text if char.isdigit())\n",
        "         print(\"총 검색 호텔 개수:\", total_result_num)\n",
        "         return int(total_result_num) // 20 + 1\n",
        "\n",
        "      except Exception as e:\n",
        "         print(f\"Error in get_total_page_num: {e}\")\n",
        "         return 0\n",
        "\n",
        "link_list = []\n",
        "\n",
        "def Crawling(region, start_date, end_date, person, total_page_num):\n",
        "    hotel_data = []\n",
        "\n",
        "    for page_num in range(1, 3): # 'total_page_num + 1'이 맞지만 시간이 오래 소요되어 일단 3으로 설정함\n",
        "        url = f\"https://www.yeogi.com/domestic-accommodations?searchType=KEYWORD&keyword={region}&autoKeyword=&checkIn={start_date}&checkOut={end_date}&personal={person}&freeForm=false&page={page_num}\"\n",
        "        print('Connecting to Scraping Browser...')\n",
        "        sbr_connection = ChromiumRemoteConnection(SBR_WEBDRIVER, 'goog', 'chrome')\n",
        "\n",
        "        with Remote(sbr_connection, options=ChromeOptions()) as driver:\n",
        "             print('Connected! Navigating...')\n",
        "             driver.get(url)\n",
        "             html = driver.page_source\n",
        "             soup = BeautifulSoup(html, \"html.parser\")\n",
        "             items = soup.select(\"[class=gc-thumbnail-type-seller-card.css-vbesvf]\")\n",
        "             print(len(items))\n",
        "\n",
        "             # 상품 접속 링크 가져오기\n",
        "             for item in items:\n",
        "                 link = f\"https://www.yeogi.com{item.get('href')}\"\n",
        "                 print(link)\n",
        "\n",
        "'''\n",
        "             time.sleep(5)\n",
        "             links = driver.find_elements(By.CSS_SELECTOR, \"a.gc-thumbnail-type-seller-card\")\n",
        "             for link in links:\n",
        "                href = link.get_attribute(\"href\")\n",
        "                driver.get(href)\n",
        "'''\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    region = input(\"지역명: \")\n",
        "    start_date = input(\"체크인 날짜(0000-00-00): \")\n",
        "    end_date = input(\"체크아웃 날짜(0000-00-00): \")\n",
        "    person = input(\"인원수: \")\n",
        "    total_page_num = get_total_page_num(region, start_date, end_date, person)\n",
        "    print(f\"총 검색 페이지 개수: {total_page_num}\")\n",
        "    if total_page_num > 0:\n",
        "        Crawling(region, start_date, end_date, person, total_page_num)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 525
        },
        "id": "P__hvOz2uThj",
        "outputId": "009d1826-df09-4c8c-d888-9683724c7ab1"
      },
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "지역명: 서울\n",
            "체크인 날짜(0000-00-00): 2024-08-17\n",
            "체크아웃 날짜(0000-00-00): 2024-08-18\n",
            "인원수: 2\n",
            "https://www.yeogi.com/domestic-accommodations?searchType=KEYWORD&keyword=서울&autoKeyword=&checkIn=2024-08-17&checkOut=2024-08-18&personal=2&freeForm=false&page=1\n",
            "Connecting to Scraping Browser...\n",
            "Connected! Navigating...\n",
            "총 검색 호텔 개수: 1164\n",
            "총 검색 페이지 개수: 59\n",
            "Connecting to Scraping Browser...\n",
            "Connected! Navigating...\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-59-8f32f63a9b9b>\u001b[0m in \u001b[0;36m<cell line: 66>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     72\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"총 검색 페이지 개수: {total_page_num}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     73\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mtotal_page_num\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 74\u001b[0;31m         \u001b[0mCrawling\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mregion\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstart_date\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mend_date\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mperson\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtotal_page_num\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-59-8f32f63a9b9b>\u001b[0m in \u001b[0;36mCrawling\u001b[0;34m(region, start_date, end_date, person, total_page_num)\u001b[0m\n\u001b[1;32m     46\u001b[0m              \u001b[0mhtml\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdriver\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpage_source\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     47\u001b[0m              \u001b[0msoup\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mBeautifulSoup\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhtml\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"html.parser\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 48\u001b[0;31m              \u001b[0mitems\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msoup\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mselect\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"[class=gc-thumbnail-type-seller-card.css-vbesvf]\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     49\u001b[0m              \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/bs4/element.py\u001b[0m in \u001b[0;36mselect\u001b[0;34m(self, selector, namespaces, limit, **kwargs)\u001b[0m\n\u001b[1;32m   2114\u001b[0m         \u001b[0;34m:\u001b[0m\u001b[0mrtype\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mbs4\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0melement\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mResultSet\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2115\u001b[0m         \"\"\"\n\u001b[0;32m-> 2116\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mselect\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mselector\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnamespaces\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlimit\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2117\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2118\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/bs4/css.py\u001b[0m in \u001b[0;36mselect\u001b[0;34m(self, select, namespaces, limit, flags, **kwargs)\u001b[0m\n\u001b[1;32m    160\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    161\u001b[0m         return self._rs(\n\u001b[0;32m--> 162\u001b[0;31m             self.api.select(\n\u001b[0m\u001b[1;32m    163\u001b[0m                 \u001b[0mselect\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtag\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_ns\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnamespaces\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mselect\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlimit\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mflags\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    164\u001b[0m                 \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/soupsieve/__init__.py\u001b[0m in \u001b[0;36mselect\u001b[0;34m(select, tag, namespaces, limit, flags, custom, **kwargs)\u001b[0m\n\u001b[1;32m    145\u001b[0m     \u001b[0;34m\"\"\"Select the specified tags.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    146\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 147\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mcompile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mselect\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnamespaces\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mflags\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mselect\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtag\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlimit\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    148\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    149\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/soupsieve/__init__.py\u001b[0m in \u001b[0;36mcompile\u001b[0;34m(pattern, namespaces, flags, custom, **kwargs)\u001b[0m\n\u001b[1;32m     63\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mpattern\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     64\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 65\u001b[0;31m     return cp._cached_css_compile(\n\u001b[0m\u001b[1;32m     66\u001b[0m         \u001b[0mpattern\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     67\u001b[0m         \u001b[0mct\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mNamespaces\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnamespaces\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mnamespaces\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mnamespaces\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/soupsieve/css_parser.py\u001b[0m in \u001b[0;36m_cached_css_compile\u001b[0;34m(pattern, namespaces, custom, flags)\u001b[0m\n\u001b[1;32m    206\u001b[0m             \u001b[0mcustom\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcustom_selectors\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    207\u001b[0m             \u001b[0mflags\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mflags\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 208\u001b[0;31m         ).process_selectors(),\n\u001b[0m\u001b[1;32m    209\u001b[0m         \u001b[0mnamespaces\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    210\u001b[0m         \u001b[0mcustom\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/soupsieve/css_parser.py\u001b[0m in \u001b[0;36mprocess_selectors\u001b[0;34m(self, index, flags)\u001b[0m\n\u001b[1;32m   1127\u001b[0m         \u001b[0;34m\"\"\"Process selectors.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1128\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1129\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparse_selectors\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mselector_iter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpattern\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mflags\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1130\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1131\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/soupsieve/css_parser.py\u001b[0m in \u001b[0;36mparse_selectors\u001b[0;34m(self, iselector, index, flags)\u001b[0m\n\u001b[1;32m    963\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    964\u001b[0m             \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 965\u001b[0;31m                 \u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mm\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miselector\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    966\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    967\u001b[0m                 \u001b[0;31m# Handle parts\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/soupsieve/css_parser.py\u001b[0m in \u001b[0;36mselector_iter\u001b[0;34m(self, pattern)\u001b[0m\n\u001b[1;32m   1097\u001b[0m             \u001b[0mm\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1098\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mv\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcss_tokens\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1099\u001b[0;31m                 \u001b[0mm\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpattern\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflags\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1100\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mm\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1101\u001b[0m                     \u001b[0mname\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_name\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/soupsieve/css_parser.py\u001b[0m in \u001b[0;36mmatch\u001b[0;34m(self, selector, index, flags)\u001b[0m\n\u001b[1;32m    306\u001b[0m         \u001b[0;34m\"\"\"Match the selector.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    307\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 308\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mre_pattern\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mselector\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    309\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    310\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 경고 문구 제거\n",
        "warnings.filterwarnings(\"ignore\", category=requests.packages.urllib3.exceptions.InsecureRequestWarning)\n",
        "\n",
        "# bright data\n",
        "AUTH = 'brd-customer-hl_6b1e4e16-zone-scraping_browser1:57gtuhxt7jou'\n",
        "SBR_WEBDRIVER = f'https://{AUTH}@zproxy.lum-superproxy.io:9515'\n",
        "\n",
        "# 총 검색 호텔 개수 및 총 검색 페이지 수 계산\n",
        "def get_total_page_num(region, start_date, end_date, person):\n",
        "  url = f\"https://www.yeogi.com/domestic-accommodations?searchType=KEYWORD&keyword={region}&autoKeyword=&checkIn={start_date}&checkOut={end_date}&personal={person}&freeForm=false&page=1\"\n",
        "  print(url)\n",
        "  print('Connecting to Scraping Browser...')\n",
        "  sbr_connection = ChromiumRemoteConnection(SBR_WEBDRIVER, 'goog', 'chrome')\n",
        "  with Remote(sbr_connection, options=ChromeOptions()) as driver:\n",
        "      print('Connected! Navigating...')\n",
        "      driver.get(url)\n",
        "      html = driver.page_source\n",
        "      soup = BeautifulSoup(html, \"html.parser\")\n",
        "\n",
        "      try:\n",
        "         WebDriverWait(driver, 10).until(EC.presence_of_element_located((By.CSS_SELECTOR, \"header.css-1psit91 h1\")))\n",
        "         h1_tag = driver.find_element(By.CSS_SELECTOR, \"header.css-1psit91 h1\")\n",
        "         total_result_text = h1_tag.text.strip()\n",
        "         total_result_num = \"\".join(char for char in total_result_text if char.isdigit())\n",
        "         print(\"총 검색 호텔 개수:\", total_result_num)\n",
        "         return int(total_result_num) // 20 + 1\n",
        "      except Exception as e:\n",
        "         print(f\"Error in get_total_page_num: {e}\")\n",
        "         return 0\n",
        "\n",
        "def Crawling(region, start_date, end_date, person, total_page_num):\n",
        "    hotel_data = []\n",
        "    for page_num in range(1, 3): # 'total_page_num + 1'이 맞지만 시간이 오래 소요되어 일단 3으로 설정함\n",
        "        url = f\"https://www.yeogi.com/domestic-accommodations?searchType=KEYWORD&keyword={region}&autoKeyword=&checkIn={start_date}&checkOut={end_date}&personal={person}&freeForm=false&page={page_num}\"\n",
        "        print('Connecting to Scraping Browser...')\n",
        "        sbr_connection = ChromiumRemoteConnection(SBR_WEBDRIVER, 'goog', 'chrome')\n",
        "        with Remote(sbr_connection, options=ChromeOptions()) as driver:\n",
        "             print('Connected! Navigating...')\n",
        "             driver.get(url)\n",
        "             html = driver.page_source\n",
        "             soup = BeautifulSoup(html, \"html.parser\")\n",
        "\n",
        "             # 페이지 로딩 대기\n",
        "             try:\n",
        "                  WebDriverWait(driver, 10).until(\n",
        "                      EC.presence_of_element_located((By.XPATH, '//script[@type=\"application/ld+json\"]'))\n",
        "                  )\n",
        "                  script_tag = driver.find_element(By.XPATH, '//script[@type=\"application/ld+json\"]')\n",
        "                  json_data = script_tag.get_attribute('innerText')\n",
        "\n",
        "                  # JSON 데이터 파싱\n",
        "                  data = json.loads(json_data)\n",
        "\n",
        "                  # 호텔/모텔 정보 추출\n",
        "                  accommodations = data['mainEntity']['itemListElement']\n",
        "                  for accommodation in accommodations:\n",
        "                      hotel_info = {}\n",
        "                      item = accommodation['item']\n",
        "                      name = item['name']\n",
        "                      url = item['url']\n",
        "                      star_rating = item['starRating']\n",
        "                      price_range = item['priceRange']\n",
        "                      address = item['address']['addressLocality']\n",
        "\n",
        "                      # 'aggregateRating' 유무 예외처리\n",
        "                      aggregate_rating = item.get('aggregateRating', None)\n",
        "                      if aggregate_rating:\n",
        "                          rating_value = aggregate_rating['ratingValue']\n",
        "                          review_count = aggregate_rating['reviewCount']\n",
        "                      else:\n",
        "                          rating_value = 'N/A'\n",
        "                          review_count = 'N/A'\n",
        "\n",
        "                      hotel_info['name'] = name\n",
        "                      hotel_info['Url'] = url\n",
        "                      hotel_info['star_rating'] = star_rating\n",
        "                      hotel_info['price'] = price_range\n",
        "                      hotel_info['Address'] = address\n",
        "                      hotel_info['Rating'] = rating_value\n",
        "                      hotel_info['review_cnt'] = review_count\n",
        "                      print(name)\n",
        "                      hotel_data.append(hotel_info)\n",
        "\n",
        "             except Exception as e:\n",
        "                      print(f\"Error in Crawling page {page_num}: {e}\")\n",
        "\n",
        "    # 전체 dict를 JSON 파일로 저장\n",
        "    with open('hotel_data.json', 'w', encoding='utf-8') as json_file:\n",
        "      json.dump(hotel_data, json_file, ensure_ascii=False, indent=4)\n",
        "\n",
        "    files.download('hotel_data.json')\n",
        "\n",
        "    return 0\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    region = input(\"지역명: \")\n",
        "    start_date = input(\"체크인 날짜(0000-00-00): \")\n",
        "    end_date = input(\"체크아웃 날짜(0000-00-00): \")\n",
        "    person = input(\"인원수: \")\n",
        "    total_page_num = get_total_page_num(region, start_date, end_date, person)\n",
        "    print(f\"총 검색 페이지 개수: {total_page_num}\")\n",
        "    if total_page_num > 0:\n",
        "        Crawling(region, start_date, end_date, person, total_page_num)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 964
        },
        "outputId": "c2454e41-ba84-4829-9a7b-41950d5003f7",
        "id": "iwcIxqOhG3n4"
      },
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "지역명: 서울\n",
            "체크인 날짜(0000-00-00): 2024-08-17\n",
            "체크아웃 날짜(0000-00-00): 2024-08-18\n",
            "인원수: 2\n",
            "https://www.yeogi.com/domestic-accommodations?searchType=KEYWORD&keyword=서울&autoKeyword=&checkIn=2024-08-17&checkOut=2024-08-18&personal=2&freeForm=false&page=1\n",
            "Connecting to Scraping Browser...\n",
            "Connected! Navigating...\n",
            "총 검색 호텔 개수: 1164\n",
            "총 검색 페이지 개수: 59\n",
            "Connecting to Scraping Browser...\n",
            "Connected! Navigating...\n",
            "서울신라호텔\n",
            "길동 MARI-마리\n",
            "스위스 그랜드 호텔\n",
            "영등포 H-AVENUE\n",
            "종로 K-World-종로 3가\n",
            "사당 호텔 카일\n",
            "신촌 라뉘호텔\n",
            "종로 부티크 호텔K\n",
            "신라스테이 구로\n",
            "신촌 바론드 호텔\n",
            "은평 씨에스에비뉴 호텔\n",
            "이비스 스타일 앰배서더 서울 용산\n",
            "영등포 Blvd 호텔오라\n",
            "잠실 NU호텔-종합운동장점\n",
            "신촌 가을\n",
            "성신여대 호텔 우디\n",
            "왕십리 포레스타\n",
            "건대 더 디자이너스 프리미어-화양동\n",
            "화곡 VOLL\n",
            "★당일특가★ 앰배서더 서울 풀만 호텔\n",
            "Connecting to Scraping Browser...\n",
            "Connected! Navigating...\n",
            "종로 브라운도트 호텔\n",
            "역삼 리치웰\n",
            "역삼 컬리넌\n",
            "역삼 인트로호텔\n",
            "강남 멜리샤호텔\n",
            "성신여대역 더월-THE WALL\n",
            "명동 밀리오레호텔\n",
            "잠실 Stay hotel\n",
            "강남 캠퍼스\n",
            "신촌 호텔 루씨르\n",
            "건대 호텔 K World\n",
            "잠실 루이체\n",
            "페어필드 바이 메리어트 서울\n",
            "종로 시네마\n",
            "종로 THE MAY HOTEL\n",
            "독산 호텔 인 카페\n",
            "영등포 더 문\n",
            "신촌 림\n",
            "잠실 라비호텔\n",
            "사당 필름 37.2\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_b8904560-5ae2-47ea-81a9-a037f3d0fac0\", \"hotel_data.json\", 12627)"
            ]
          },
          "metadata": {}
        }
      ]
    }
  ]
}